#!/Users/calebfaruki/study/enkodo/.venv/bin/python3
"""
Usage:
    enkodo analyze <filename>
    enkodo band <filename>
    enkodo deband <filename>
    enkodo interlace <filename>
    enkodo deinterlace <filename>
    enkodo block <filename>
    enkodo deblock <filename>
"""

import os
import subprocess
import json
from dataclasses import dataclass
from docopt import docopt
import vapoursynth as vs
core = vs.core

@dataclass
class VideoAnalysis:
    container: str
    codec: str
    resolution: str
    duration: str
    bitrate: int # kbps
    bit_depth: int # number of color levels
    framerate: int

def main():
    arguments = docopt(__doc__)

    if arguments['analyze']:
        analysis = analyze(arguments)
        print(analysis)
    elif arguments["band"]:
        band(arguments)
    elif arguments["deband"]:
        deband(arguments)
    elif arguments["interlace"]:
        interlace(arguments)
    elif arguments["deinterlace"]:
        deinterlace(arguments)
    elif arguments["block"]:
        block(arguments)
    elif arguments["deblock"]:
        deblock(arguments)

def analyze(arguments) -> VideoAnalysis:
    print("Analyzing...")

    filename = arguments['<filename>']

    command = f"""
        ffprobe -print_format json -show_format -show_streams -v quiet {filename}
    """

    result = subprocess.run(command, capture_output=True, shell=True)
    
    parsed_result = json.loads(result.stdout)

    # Get container
    container = parsed_result["format"]["format_long_name"]

    streams = parsed_result["streams"]

    # Find default video stream.
    vstream = [stream for stream in streams if stream["codec_type"] == "video" and stream["disposition"]["default"] == 1][0]

    # Get resolution
    height = vstream["height"]
    width = vstream["width"]
    resolution = f"{height}x{width}"

    # Get duration
    total_seconds = int(float(vstream["duration"]))
    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    duration = f"{hours:02d}:{minutes:02d}:{seconds:02d}"

    # Get bitrate in kbps
    bitrate = int(vstream["bit_rate"])

    # Get color levels (bit depth)
    bit_depth = int(vstream["bits_per_raw_sample"])

    analysis = VideoAnalysis(
        container=container,
        codec=vstream["codec_name"],
        resolution=resolution,
        duration=duration,
        bitrate=bitrate,
        bit_depth=bit_depth,
        framerate=int(vstream["r_frame_rate"].split("/")[0])
    )
    return analysis

def band(arguments):
    filename = arguments["<filename>"]
    analysis = analyze(arguments)

    clip = load_clip(filename)

    # Calculate divisor based on bit depth
    target_levels = 32
    current_levels = 2 ** analysis.bit_depth
    divisor = current_levels // target_levels

    clip = core.std.Lut(clip, function=lambda x: (x // divisor) * divisor)

    pipe_to_ffmpeg(clip, "examples/banding/banded.mp4", crf=26)

def deband(arguments):
    filename = arguments['<filename>']
    analysis = analyze(arguments)

    original_bit_depth = analysis.bit_depth

    clip = load_clip(filename)

    # Convert to 16 bit color depth for gradient calculation
    if original_bit_depth < 16:
        clip = core.fmtc.bitdepth(clip, bits=16)

    # Use f3kdb to detect banding and smooth it out
    clip = core.neo_f3kdb.Deband(
        clip,
        range=31, # pixel radius for gradient detection
        y=255, # Luma strength, (moderate, not extreme)
        cb=255, # Chroma blue strength
        cr=255, # Chroma red strength
        grainy=255, # Luma grain to mask smoothing
        grainc=255, # Chroma gain
        output_depth=16
    )

    # Sanity check
    # clip = core.std.Invert(clip)

    # If original bit depth < 16 bit depth, convert back with dithering
    # to add appearance of smooth gradients despite fewere color levels.
    if original_bit_depth < 16:
        clip = core.fmtc.bitdepth(clip, bits=original_bit_depth, dmode=6)

    pipe_to_ffmpeg(clip, "examples/banding/debanded.mp4", crf=26)

def interlace(arguments):
    print("Interlacing...")
    filename = arguments["<filename>"]
    
    command = f"""
        ffmpeg -y -i {filename} -vf "tinterlace=mode=interleave_top" -c:v libx264 -crf 12 examples/interlacing/interlaced.mp4
    """
    subprocess.run(command, shell=True)

def deinterlace(arguments):
    filename = arguments["<filename>"]

    clip = load_clip(filename)

    # Use OpenCL version - no weights file needed
    clip = core.nnedi3cl.NNEDI3CL(clip, field=1)

    pipe_to_ffmpeg(clip, "examples/interlacing/deinterlaced.mp4")

def block(arguments):
    print("Blocking...")
    filename = arguments["<filename>"]

    # Throttle bitrate and disable built-in h.264 deblocking
    command = f"""
        ffmpeg -y -i {filename} -c:v libx264 -b:v 800k -x264-params no-deblock=1 -preset ultrafast examples/blocking/blocked.mp4
    """

    subprocess.run(command, shell=True)

def deblock(arguments):
    print("Deblocking...")
    filename = arguments["<filename>"]

    clip = load_clip(filename)

    # quant: 0-60, higher = stronger deblocking
    clip = core.deblock.Deblock(clip, quant=60)

    pipe_to_ffmpeg(clip, "examples/blocking/deblocked.mp4", crf=20)

def pipe_to_ffmpeg(clip, output_filename, crf=12):
    clip.set_output()

    command = f"""
        ffmpeg -y -f yuv4mpegpipe -i - -c:v libx264 -crf {crf} -pix_fmt yuv420p {output_filename}
    """
    ffmpeg = subprocess.Popen(command, stdin=subprocess.PIPE, shell=True)
    clip.output(ffmpeg.stdin, y4m=True)
    ffmpeg.communicate()

def load_clip(filename):
    return core.lsmas.LWLibavSource(filename, cachefile=f"/tmp/{os.path.basename(filename)}.lwi")

if __name__ == "__main__":
    main()
